{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Fine-tuning your model"},{"metadata":{},"cell_type":"markdown","source":"### How good is your model?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dia = pd.read_csv('../input/diabetes/diabetes.csv')\ndia.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ['pregnancies', 'glucose', 'diastolic', 'triceps', 'insulin', 'bmi', 'dpf', 'age']\n\ny = dia['diabetes']\n\nX = dia.drop(['diabetes'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# Create training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.4)\n\n# Instantiate a k-NN classifier: knn\nknn = KNeighborsClassifier(n_neighbors=6)\n\n# Fit the classifier to the training data\nknn.fit(X_train, y_train)\n\n# Predict the labels of the test data: y_pred\ny_pred = knn.predict(X_test)\n\n# Generate the confusion matrix and classification report\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic regression and the ROC curve\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the necessary modules\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Create training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n\n# Create the classifier: logreg\nlogreg = LogisticRegression()\n\n# Fit the classifier to the training data\nlogreg.fit(X_train, y_train)\n\n# Predict the labels of the test set: y_pred\ny_pred = logreg.predict(X_test)\n\n# Compute and print the confusion matrix and classification report\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You now know how to use logistic regression for binary classification."},{"metadata":{},"cell_type":"markdown","source":"### Plotting an ROC curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\n\n# Compute predicted probabilities: y_pred_prob\ny_pred_prob = logreg.predict_proba(X_test)[:,1]\n\n# Generate ROC curve values: fpr, tpr, thresholds\nfpr, tpr, threashold = roc_curve(y_test, y_pred_prob)\n\n# Plot ROC curve\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This ROC curve provides a nice visual way to assess your classifier's performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threashold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A recall of 1 corresponds to a classifier with a low threshold in which all females who contract diabetes were correctly classified as such, at the expense of many misclassifications of those who did not have diabetes.\n\n    This is actually a true statement! Observe how when the recall is high, the precision drops.\n\nPrecision is undefined for a classifier which makes no positive predictions, that is, classifies everyone as not having diabetes.\n    \n    In the case when there are no true positives or true negatives, precision is 0/0, which is undefined.\n\n\nWhen the threshold is very close to 1, precision is also 1, because the classifier is absolutely certain about its predictions.\n\n    This is a correct statement. Notice how a high precision corresponds to a low recall: The classifier has a \n    high threshold to ensure the positive predictions it makes are correct, which means it may miss some positive labels that have lower probabilities.\n\n"},{"metadata":{},"cell_type":"markdown","source":"### AUC computation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\n\n# Compute predicted probabilities: y_pred_prob\ny_pred_prob = logreg.predict_proba(X_test)[:,1]\n\n# Compute and print AUC score\nprint(\"AUC: {}\".format(roc_auc_score(y_test,y_pred_prob)))\n\n# Compute cross-validated AUC scores: cv_auc\ncv_auc = cross_val_score(logreg, X, y, cv=5, scoring='roc_auc')\n\n# Print list of AUC scores\nprint(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter tuning with GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\n\n# Setup the hyperparameter grid\nc_space = np.logspace(-5, 8, 15)\nparam_grid = {'C': c_space}\n\n# Instantiate a logistic regression classifier: logreg\nlogreg = LogisticRegression()\n\n# Instantiate the GridSearchCV object: logreg_cv\nlogreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n\n# Fit it to the data\nlogreg_cv.fit(X,y)\n\n# Print the tuned parameters and score\nprint(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \nprint(\"Best score is {}\".format(logreg_cv.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like a 'C' of 268.27 results in the best performance."},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter tuning with RandomizedSearchCV\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom scipy.stats import randint\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Setup the parameters and distributions to sample from: param_dist\nparam_dist = {\"max_depth\": [3, None],\n              \"max_features\": randint(1, 9),\n              \"min_samples_leaf\": randint(1, 9),\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n# Instantiate a Decision Tree classifier: tree\ntree = DecisionTreeClassifier()\n\n# Instantiate the RandomizedSearchCV object: tree_cv\ntree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n\n# Fit it to the data\ntree_cv.fit(X,y)\n\n# Print the tuned parameters and score\nprint(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\nprint(\"Best score is {}\".format(tree_cv.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomizedSearchCV will never outperform GridSearchCV. Instead, it is valuable because it saves on computation time."},{"metadata":{},"cell_type":"markdown","source":"### Hold-out set in practice I: Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n# Create the hyperparameter grid\nc_space = np.logspace(-5, 8, 15)\nparam_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n\n# Instantiate the logistic regression classifier: logreg\nlogreg = LogisticRegression()\n\n# Create train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.4, random_state=42)\n\n# Instantiate the GridSearchCV object: logreg_cv\nlogreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n\n# Fit it to the training data\nlogreg_cv.fit(X_train, y_train)\n\n# Print the optimal parameters and best score\nprint(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\nprint(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hold-out set in practice II: Regression\n\nLasso used the L1 penalty to regularize, while ridge used the L2 penalty. In elastic net regularization, the penalty term is a linear combination of the L1 and L2 penalties"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the CSV file into a DataFrame: df\ndf = pd.read_csv('../input/gapminder/gapminder.csv')\n\n# Create arrays for features and target variable\ny = df.life\nX = df.drop(['life', 'Region'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\n# Create train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Create the hyperparameter grid\nl1_space = np.linspace(0, 1, 30)\nparam_grid = {'l1_ratio': l1_space}\n\n# Instantiate the ElasticNet regressor: elastic_net\nelastic_net = ElasticNet()\n\n# Setup the GridSearchCV object: gm_cv\ngm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n\n# Fit it to the training data\ngm_cv.fit(X_train,y_train)\n\n# Predict on the test set and compute metrics\ny_pred = gm_cv.predict(X_test)\nr2 = gm_cv.score(X_test, y_test)\nmse = mean_squared_error(y_test, y_pred)\n\nprint(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\nprint(\"Tuned ElasticNet R squared: {}\".format(r2))\nprint(\"Tuned ElasticNet MSE: {}\".format(mse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}
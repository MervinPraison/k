{"cells":[{"metadata":{},"cell_type":"markdown","source":"1. # Introduction to TensorFlow "},{"metadata":{},"cell_type":"markdown","source":"Note that we have not imported the entire tensorflow API and will not import it for most exercises. You can complete this exercise using the operations fill(), ones_like(), and constant(), which have been imported from tensorflow version 2.0 and are available in the IPython shell."},{"metadata":{},"cell_type":"markdown","source":"## Define Variables "},{"metadata":{"ExecuteTime":{"end_time":"2019-06-09T13:01:37.033811Z","start_time":"2019-06-09T13:01:37.001369Z"}},"cell_type":"raw","source":"# Define a 3x4 tensor with all values equal to 9\nx = fill([3, 4], 9)\n\n# Define a tensor of ones with the same shape as x\ny = ones_like(x)\n\n# Define the one-dimensional vector, z\nz = constant([1, 2, 3, 4])\n\n# Print z as a numpy array\nprint(z.numpy())"},{"metadata":{},"cell_type":"raw","source":"# Define the 1-dimensional variable X\nX = Variable([1, 2, 3, 4])\n\n# Print the variable X\nprint(X)\n\n# Convert X to a numpy array and assign it to Z\nZ = X.numpy()\n\n# Print Z\nprint(Z)"},{"metadata":{},"cell_type":"markdown","source":"## Basic operations "},{"metadata":{},"cell_type":"markdown","source":"add() performs element-wise addition with two tensors. It requires both tensors to have the same shape."},{"metadata":{},"cell_type":"markdown","source":"multiply() performs element-wise multiplication. Both tensors must have the same shape."},{"metadata":{},"cell_type":"markdown","source":"matmul() performs matrix multiplication."},{"metadata":{},"cell_type":"markdown","source":"reduce_sum() sums over the dimensions of a tensor. reduce_sum(A) sums over all dimensions of A. reduce_sum(A, i) sums over dimension i."},{"metadata":{},"cell_type":"markdown","source":"## Advanced operations "},{"metadata":{},"cell_type":"markdown","source":"gradient(): computes the slope of a function at a point"},{"metadata":{},"cell_type":"markdown","source":"reshape(): reshapes a tensor"},{"metadata":{},"cell_type":"markdown","source":"random(): populates tensor with entries drawn from a probability distribution"},{"metadata":{},"cell_type":"markdown","source":"Finding the optimum: maximum: lowest value of a loss function, maximum: highest value of objective function"},{"metadata":{},"cell_type":"markdown","source":"optimum: find a point where gradient=0, minimum change in gradient>0, maximum change in gradient<0"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T12:06:12.230805Z","start_time":"2019-06-10T12:06:12.211123Z"},"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import Variable\nimport numpy as np\n\n# define x\nx = tf.Variable(-1.0)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T12:06:12.627581Z","start_time":"2019-06-10T12:06:12.608124Z"},"trusted":true},"cell_type":"code","source":"# define y within instance of GradientTape\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.multiply(x, x)\n    \n# evaluate the gradient of y at x = -1\ng = tape.gradient(y, x)\nprint(g)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the slope is -2."},{"metadata":{},"cell_type":"markdown","source":"How to reshape a grayscale image"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T12:09:35.508523Z","start_time":"2019-06-10T12:09:35.485976Z"},"trusted":true},"cell_type":"code","source":"# generate grayscale image\ngray = tf.random.uniform([2, 2], maxval=255, dtype='int32')\ngray","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T12:09:40.436154Z","start_time":"2019-06-10T12:09:40.423419Z"},"trusted":true},"cell_type":"code","source":"# reshape image\ngray = tf.reshape(gray, [2*2, 1])\ngray","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reshape a color image"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T12:11:31.736780Z","start_time":"2019-06-10T12:11:31.722932Z"},"trusted":true},"cell_type":"code","source":"# generate color image\ncolor = tf.random.uniform([2, 2, 3], maxval=255, dtype='int32')\ncolor","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T12:11:54.990322Z","start_time":"2019-06-10T12:11:54.977238Z"},"trusted":true},"cell_type":"code","source":"# reshape color image\ncolor = tf.reshape(color, [2*2, 3])\ncolor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression in TensorFlow "},{"metadata":{},"cell_type":"markdown","source":"## Input data "},{"metadata":{},"cell_type":"markdown","source":"Numeric data, image data, text data."},{"metadata":{},"cell_type":"markdown","source":"How to import and convert data: load data using pd, then convert it to numpy array."},{"metadata":{},"cell_type":"markdown","source":"Parameters of read_csv(): "},{"metadata":{},"cell_type":"markdown","source":"filepath_or_buffer: accepts a file path or URL, default None"},{"metadata":{},"cell_type":"markdown","source":"seo: delimiter between columns, default ,"},{"metadata":{},"cell_type":"markdown","source":"delim_whitespace: Boolean for whether to delimit whitespace, default False"},{"metadata":{},"cell_type":"markdown","source":"encoding: specifies encoding to be used if any, default None"},{"metadata":{},"cell_type":"markdown","source":"Using tf.cast():"},{"metadata":{},"cell_type":"raw","source":"# load KC dataset\nhousing = pd.read_csv('kc_housing.csv')\n\n# convert price column to float32\nprice = tf.cast(housing['price'], tf.float32)\n\n# convert waterfront column to Boolean\nwaterfront = tf.cast(housing['waterfront'], tf.bool)"},{"metadata":{},"cell_type":"markdown","source":"## Loss functions "},{"metadata":{},"cell_type":"markdown","source":"Higher value -> worse fit. Minimize the loss function."},{"metadata":{},"cell_type":"markdown","source":"Common loss functions: MSE, MAE, Huber error. Accessible from tf.keras.losses(): "},{"metadata":{},"cell_type":"raw","source":"# define a loss function to compute the MSE\ndef loss_function(intercept, slope, target, features):\n    # compute the predictions for a linear model\n    predictions = intercept + features * slope\n    # return the loss\n    return tf.keras.losses.mse(target,predictions)"},{"metadata":{},"cell_type":"markdown","source":"Other loss functions; MAPE, MSLE"},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression "},{"metadata":{},"cell_type":"markdown","source":"Example: price = intercept + size * slope + error"},{"metadata":{},"cell_type":"markdown","source":"This is an example of a univariate regression: only one feature size. Multiple regression models have more than one feature."},{"metadata":{},"cell_type":"raw","source":"# define the targets and features\nprice = np.array(housing['price'], np.float32)\nsize = np.array(housing['sqft_living'], np.float32)\n\n# define the intercept and slope\nintercept = tf.Variable(0.1, np.float32)\nslope = tf.Variable(0.1, np.float32)\n\n# compute the predicted values and loss function\ndef loss_function(intercept, slope, size, price)\n    predictions = intercept + size * slope\n    return tf.keras.losses.mse(price, predictions)"},{"metadata":{},"cell_type":"raw","source":"# define an optimization operation\nopt = tf.keras.optimizers.Adam()\n\n# minimize the loss function and print the loss\nfor j in range(1000):\n    opt.minimize(lambda: loss_function(intercept, slope, size, price), var_list = [intercept, slope])\n    print(loss_function(intercept, slope, size, price))"},{"metadata":{},"cell_type":"markdown","source":"## Batch training "},{"metadata":{},"cell_type":"markdown","source":"The chunksize parameter"},{"metadata":{},"cell_type":"markdown","source":"Training a linear model in batches"},{"metadata":{},"cell_type":"raw","source":"# load data in batches\nfor batch in pd.read_csv('kc_housing.csv', chunksize=100) # one hundred batches\n    # extract the target and feature column\n    price_batch = np.array(batch['price'], np.float32)\n    size_batch = np.array(batch['size'], np.float32)\n    # minimize the loss function\n    opt.minimize(lambda: loss_function(intercept, slope, size_batch, price_batch), var_list=[intercept, slope])"},{"metadata":{},"cell_type":"markdown","source":"# Neural Network in TensorFlow "},{"metadata":{},"cell_type":"markdown","source":"## Dense layers "},{"metadata":{},"cell_type":"markdown","source":"Three types of layers: input layer, dense layer, output layer."},{"metadata":{},"cell_type":"markdown","source":"The dense layers apply weights to all nodes..."},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T13:16:04.404127Z","start_time":"2019-06-10T13:16:04.391884Z"},"trusted":true},"cell_type":"code","source":"# define input data\ninputs = tf.constant([[1.0, 35.0]])\n\n# define weights\nweights = tf.Variable([[-0.05], [-0.01]])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T13:16:04.781153Z","start_time":"2019-06-10T13:16:04.764409Z"},"trusted":true},"cell_type":"code","source":"# multiply inputs by the weights\nproduct = tf.matmul(inputs, weights)\n\n# define dense layer\ndense = tf.keras.activations.sigmoid(product)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining a complete model"},{"metadata":{},"cell_type":"raw","source":"# define input layer\ninputs = tf.constant(data, tf.float32)\n\n# define first dense layer\ndense1 = tf.keras.layers.Dense(10, activation='sigmoid')(inputs)\n\n# define second dense layer\ndense2 = tf.keras.layers.Dense(5, activation='sigmoid')(dense1)\n\n# define output layer\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)"},{"metadata":{},"cell_type":"markdown","source":"High-level versus low-level approach: keras.layers.Dense() vs keras.activations.sigmoid()"},{"metadata":{},"cell_type":"markdown","source":"## Activation functions "},{"metadata":{},"cell_type":"markdown","source":"Components of a typical hidden layer: linear (matmul), nonlinear (activation function)."},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T13:26:33.129985Z","start_time":"2019-06-10T13:26:33.122326Z"},"trusted":true},"cell_type":"code","source":"# define example borrower features\nyoung, old = 0.3, 0.6\nlow_bill, high_bill = 0.1, 0.5\n\n# compute products and sums\nyoung_high = 1.0*young + 1.0*high_bill\nyoung_low = 1.0*young + 1.0*low_bill\nold_high = 1.0*old + 1.0*high_bill\nold_low = 1.0*old + 1.0*low_bill","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T13:27:14.537694Z","start_time":"2019-06-10T13:27:14.530484Z"},"trusted":true},"cell_type":"code","source":"# print difference for young\nprint(young_high - young_low)\n# print difference for old\nprint(old_high - old_low)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T13:29:03.409754Z","start_time":"2019-06-10T13:29:03.398665Z"},"trusted":true},"cell_type":"code","source":"# print difference for young after activation is applied\nprint(tf.keras.activations.sigmoid(young_high).numpy() - tf.keras.activations.sigmoid(young_low).numpy())\n# print difference for old after activation is applied\nprint(tf.keras.activations.sigmoid(old_high).numpy() - tf.keras.activations.sigmoid(old_low).numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sigmoid activation function: binary classification"},{"metadata":{},"cell_type":"markdown","source":"The ReLu activation function: hidden layers"},{"metadata":{},"cell_type":"markdown","source":"The softmax activation function: output layer (> 2 classes, classification)"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T13:31:38.589822Z","start_time":"2019-06-10T13:31:38.559536Z"}},"cell_type":"raw","source":"# define input layer\ninputs = tf.constant(borrower_features, tf.float32)\n\n# define dense layer 1\ndense1 = tf.keras.layers.Dense(16, activation='relu')(inputs)\n\n# define dense layer 2\ndense2 = tf.keras.layers.Dense(8, activation='sigmoid')(dense1)\n\n# define output layer\noutputs = tf.keras.layers.Dense(4, activation='softmax')(dense2)"},{"metadata":{},"cell_type":"markdown","source":"## Optimizers "},{"metadata":{},"cell_type":"markdown","source":"SGD: learning_rate"},{"metadata":{},"cell_type":"markdown","source":"Root mean squared propagation optimizer (RMSprop): applies different learning rates to each feature, decay"},{"metadata":{},"cell_type":"markdown","source":"Adam optimizer: learning_rate, beta1, beta2"},{"metadata":{},"cell_type":"raw","source":"# compute the predicted values and loss\ndef loss_function(weights):\n    product = tf.matmul(borrower_features, weights)\n    predictions = tf.keras.activations.sigmoid(product)\n    return tf.keras.losses.binary_crossentropy(default, predictions)\n\n# minimize the loss function with adam\nopt = tf.keras.optimizers.Adam(lr=0.1, beta_1=0.2, beta_2=0.8)\nopt.minimize(lambda: loss_function(weights), var_list=[weights])"},{"metadata":{},"cell_type":"markdown","source":"## Training a network in TensorFlow "},{"metadata":{},"cell_type":"markdown","source":"Random initializers: often need to initialize thousands of variables; tf.ones() may perform poorly; tedious and difficult to initialize variables individually."},{"metadata":{},"cell_type":"markdown","source":"Alternatively, draw initial values from distribution: random normal, uniform, Glorot initializer."},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T13:55:12.710702Z","start_time":"2019-06-10T13:55:12.690317Z"},"trusted":true},"cell_type":"code","source":"# define 500x500 random normal variable\nweights = tf.Variable(tf.random.normal([500, 500]))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T13:55:27.394909Z","start_time":"2019-06-10T13:55:27.375574Z"},"trusted":true},"cell_type":"code","source":"# define 500x500 truncated random normal variable\nweights = tf.Variable(tf.random.truncated_normal([500, 500]))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T13:56:29.918156Z","start_time":"2019-06-10T13:56:29.820594Z"},"trusted":true},"cell_type":"code","source":"# define a dense layer with the zeros initializer\ndense = tf.keras.layers.Dense(32, activation='relu', kernel_initializer='zeros')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overfitting: applying dropout before the output layer"},{"metadata":{},"cell_type":"raw","source":"# define input data\ninputs = np.array(borrower_features, np.float32)\n\n# define dense layer 1\ndense1 = tf.keras.layers.Dense(32, activation='relu')(inputs)\n\n# define dense layer 2\ndense1 = tf.keras.layers.Dense(16, activation='relu')(dense1)\n\n# apply dropout operation\ndropout1 = tf.keras.layers.Dropout(0.25)(dense2)\n\n# define output layer\noutputs = tf.layers.Dense(1, activation='sigmoid')(dropout1)"},{"metadata":{},"cell_type":"markdown","source":"# High Level APIs in TensorFlow "},{"metadata":{},"cell_type":"markdown","source":"## Defining neural networks with Keras "},{"metadata":{},"cell_type":"markdown","source":"Build a sequential model, using the MNIST sign language dataset."},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:15:16.198083Z","start_time":"2019-06-10T14:15:16.097745Z"},"trusted":true},"cell_type":"code","source":"# define a sequential model\nmodel = tf.keras.Sequential()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:16:10.947279Z","start_time":"2019-06-10T14:16:10.779271Z"},"trusted":true},"cell_type":"code","source":"# define first hidden layer\nmodel.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(28*28,)))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:17:09.278894Z","start_time":"2019-06-10T14:17:09.225581Z"},"trusted":true},"cell_type":"code","source":"# define second hidden layer\nmodel.add(tf.keras.layers.Dense(8, activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:17:30.275478Z","start_time":"2019-06-10T14:17:30.228938Z"},"trusted":true},"cell_type":"code","source":"# define output layer\nmodel.add(tf.keras.layers.Dense(4, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:17:56.115752Z","start_time":"2019-06-10T14:17:55.993664Z"},"trusted":true},"cell_type":"code","source":"# compile the model\nmodel.compile('adam', loss='categorical_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What if you want to train 2 models joined to predict the same target?"},{"metadata":{},"cell_type":"markdown","source":"Using the functional API"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:22:26.884544Z","start_time":"2019-06-10T14:22:26.782793Z"},"trusted":true},"cell_type":"code","source":"# define model 1, 2 input layer shape\nmodel1_inputs = tf.keras.Input(shape=(28*28,))\nmodel2_inputs = tf.keras.Input(shape=(10,))\n\n# define layer 1, 2 for model 1\nmodel1_layer1 = tf.keras.layers.Dense(12, activation='relu')(model1_inputs)\nmodel1_layer2 = tf.keras.layers.Dense(4, activation='softmax')(model1_layer1)\n\n# define layer 1, 2 for model 2\nmodel2_layer1 = tf.keras.layers.Dense(8, activation='relu')(model2_inputs)\nmodel2_layer2 = tf.keras.layers.Dense(4, activation='softmax')(model2_layer1)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:22:27.352852Z","start_time":"2019-06-10T14:22:27.324104Z"},"trusted":true},"cell_type":"code","source":"# merge model 1 and model 2\nmerged = tf.keras.layers.add([model1_layer2, model2_layer2])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:23:18.755533Z","start_time":"2019-06-10T14:23:18.650122Z"},"trusted":true},"cell_type":"code","source":"# define a functional model\nmodel = tf.keras.Model(inputs=[model1_inputs, model2_inputs], outputs=merged)\n\n# compile the model\nmodel.compile('adam', loss='categorical_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:25:31.794744Z","start_time":"2019-06-10T14:25:31.780843Z"},"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training and validation with Keras "},{"metadata":{},"cell_type":"markdown","source":"Load and clean data, define model, train and validate model, evaluate model"},{"metadata":{},"cell_type":"markdown","source":"How to train a model"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:29:38.645573Z","start_time":"2019-06-10T14:29:38.557512Z"},"trusted":true},"cell_type":"code","source":"# define a sequential model\nmodel = tf.keras.Sequential()\n\n# define the hidden layer\nmodel.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n\n# define the output layer\nmodel.add(tf.keras.layers.Dense(4, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-10T14:30:14.169887Z","start_time":"2019-06-10T14:30:13.585907Z"}},"cell_type":"raw","source":"# compile mode\nmodel.compile('adam', loss='categorical_crossentropy')\n\n# train model\nmodel.fit(image_features, image_labels)"},{"metadata":{},"cell_type":"markdown","source":"The fit() operation arguments: features, labels, batch_size, epochs, validation_split"},{"metadata":{},"cell_type":"markdown","source":"Batch size and epochs"},{"metadata":{},"cell_type":"markdown","source":"Performing validation: splitting the dataset into training set and validation set."},{"metadata":{},"cell_type":"raw","source":"# train model with validation split\nmodel.fit(features, labels, epochs=10, validation_split=0.20)"},{"metadata":{},"cell_type":"markdown","source":"Changing the metric"},{"metadata":{},"cell_type":"raw","source":"# recompile the model with the accuracy metric\nmodel.compile('adam', loss='categorical_crossentropy, metrics=['accuracy'])"},{"metadata":{},"cell_type":"markdown","source":"Use evaluation() for the test set"},{"metadata":{},"cell_type":"raw","source":"# evaluate the test set\nmodel.evaluate(test)"},{"metadata":{},"cell_type":"markdown","source":"## Training models with the Estimators API "},{"metadata":{},"cell_type":"markdown","source":"Low-Level TF APIs: Python"},{"metadata":{},"cell_type":"markdown","source":"Mid-Level TF APIs: Layers, Datasets, Metrics"},{"metadata":{},"cell_type":"markdown","source":"High-Level TF APIs: Estimators"},{"metadata":{},"cell_type":"markdown","source":"Estimators API: high level submodule, less flexible, enforces best practices, faster deployment, many premade models"},{"metadata":{},"cell_type":"markdown","source":"Model specification and training: define feature columns, load and transform data, define an estimator, apply train operation"},{"metadata":{},"cell_type":"raw","source":"# define a numeric feature column\nsize = tf.feature_column.nimeric_column('size')\n\n# define a categorical feature column\nrooms = tf.feature_column.categorical_column_with_vocabulary_list('rooms', ['1', '2', '3', '4', '5'])\n\n# create feature column list\nfeatures_list = [size, rooms]\n\n# define a matrix feature column\nfeatures_list = [tf.feature_column.numeric_column('image', shape=(784,))]\n\n# define input data function\ndef input_fn():\n    # define feature dictionary\n    features = {'size':[1340, 1690, 2720], 'rooms':[1, 3, 4]}\n    # define labels\n    labels = [221900, 538000, 180000]\n    return features, labels\n    \n# define a deep neural network regression\nmodel1 = tf.estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[32, 16, 8], n_classes=4)\n\n# train the classifier\nmodel1.train(input_fn, steps=20)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}